<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>NVIDIA GPU架构 | JrunDing</title><meta name="author" content="JrunDing"><meta name="copyright" content="JrunDing"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="NVIDIA GPU的架构演变历史和基本概念截止2021年，发布时间离我们最近的8种NVIDIA GPU微架构是：  Tesla Fermi Kepler Maxwell Pascal Volta Turing Ampere  NVIDIA一般以历史上一些著名科学家的名字命名自己的GPU微架构，上面8种微架构分别是：特斯拉，费米，开普勒，麦克斯韦，帕斯卡，伏打，图灵，安培。 其中最新的是2020">
<meta property="og:type" content="article">
<meta property="og:title" content="NVIDIA GPU架构">
<meta property="og:url" content="http://jrunding.github.io/2023/11/02/NVIDIA-GPU%E6%9E%B6%E6%9E%84/index.html">
<meta property="og:site_name" content="JrunDing">
<meta property="og:description" content="NVIDIA GPU的架构演变历史和基本概念截止2021年，发布时间离我们最近的8种NVIDIA GPU微架构是：  Tesla Fermi Kepler Maxwell Pascal Volta Turing Ampere  NVIDIA一般以历史上一些著名科学家的名字命名自己的GPU微架构，上面8种微架构分别是：特斯拉，费米，开普勒，麦克斯韦，帕斯卡，伏打，图灵，安培。 其中最新的是2020">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://z1.ax1x.com/2023/12/10/piRckct.jpg">
<meta property="article:published_time" content="2023-11-02T13:49:22.000Z">
<meta property="article:modified_time" content="2023-11-02T14:39:57.016Z">
<meta property="article:author" content="JrunDing">
<meta property="article:tag" content="Communication, Automation, ML, DL, NLP, CV, Movie, photography">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://z1.ax1x.com/2023/12/10/piRckct.jpg"><link rel="shortcut icon" href="https://z1.ax1x.com/2023/11/13/piJMDnH.jpg"><link rel="canonical" href="http://jrunding.github.io/2023/11/02/NVIDIA-GPU%E6%9E%B6%E6%9E%84/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: JrunDing","link":"链接: ","source":"来源: JrunDing","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'NVIDIA GPU架构',
  isPost: true,
  isHome: false,
  isHighlightShrink: undefined,
  isToc: true,
  postUpdate: '2023-11-02 22:39:57'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://z1.ax1x.com/2023/11/13/piJMDnH.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">202</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><span> Talk</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span> Music</span></a></div><div class="menus_item"><a class="site-page" href="/movie/"><span> Movie</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://z1.ax1x.com/2023/12/10/piRckct.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="JrunDing"></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><span> Talk</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span> Music</span></a></div><div class="menus_item"><a class="site-page" href="/movie/"><span> Movie</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">NVIDIA GPU架构</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-11-02T13:49:22.000Z" title="发表于 2023-11-02 21:49:22">2023-11-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-11-02T14:39:57.016Z" title="更新于 2023-11-02 22:39:57">2023-11-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hardware/">Hardware</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">1.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>6分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="NVIDIA GPU架构"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><span class="disqus-comment-count"><a href="http://jrunding.github.io/2023/11/02/NVIDIA-GPU%E6%9E%B6%E6%9E%84/#disqus_thread"><i class="fa-solid fa-spinner fa-spin"></i></a></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><img src="https://z1.ax1x.com/2023/11/02/piKHG6O.png"></p>
<h2 id="NVIDIA-GPU的架构演变历史和基本概念"><a href="#NVIDIA-GPU的架构演变历史和基本概念" class="headerlink" title="NVIDIA GPU的架构演变历史和基本概念"></a>NVIDIA GPU的架构演变历史和基本概念</h2><p>截止2021年，发布时间离我们最近的8种NVIDIA GPU微架构是：</p>
<ul>
<li><strong>Tesla</strong></li>
<li><strong>Fermi</strong></li>
<li><strong>Kepler</strong></li>
<li><strong>Maxwell</strong></li>
<li><strong>Pascal</strong></li>
<li><strong>Volta</strong></li>
<li><strong>Turing</strong></li>
<li><strong>Ampere</strong></li>
</ul>
<p>NVIDIA一般以历史上一些著名科学家的名字命名自己的GPU微架构，上面8种微架构分别是：<strong>特斯拉</strong>，<strong>费米</strong>，<strong>开普勒</strong>，<strong>麦克斯韦</strong>，<strong>帕斯卡</strong>，<strong>伏打</strong>，<strong>图灵</strong>，<strong>安培</strong>。</p>
<p>其中最新的是2020年宣布的Ampere架构。</p>
<h2 id="Tesla-架构"><a href="#Tesla-架构" class="headerlink" title="Tesla 架构"></a>Tesla 架构</h2><p>Tesla 架构的资料在官网也没找到多少，不过这是英伟达第一个实现<strong>统一着色器模型</strong>的微架构。</p>
<p>经典型号是<strong>G80</strong>，在Fermi架构白皮书的开篇部分有对G80的简要介绍：</p>
<ul>
<li>G80 是第一款支持 C 语言的 GPU，让程序员无需学习新的编程语言即可使用GPU的强大功能。</li>
<li>G80 是第一款用单一、统一的处理器取代独立的顶点和像素管道的 GPU，该处理器可以执行顶点、几何、像素和计算程序。</li>
<li>G80 是第一款使用标量线程处理器的 GPU，无需程序员手动管理向量寄存器</li>
<li>G80 引入了单指令多线程 (SIMT) 执行模型，即多个独立线程使用一条指令并发执行。</li>
<li>G80 为线程间通信引入了共享内存(shared memory)和屏障同步(barrier synchronization)。</li>
</ul>
<h2 id="Fermi架构"><a href="#Fermi架构" class="headerlink" title="Fermi架构"></a>Fermi架构</h2><p>Fermi 架构是NVIDIA GPU 架构自初代 G80 以来最重大的飞跃。</p>
<p>NVIDIA的GPU研发团队从G80和GT200两个型号上汲取经验，采用全新的设计方法来创建世界上第一个计算 GPU。在这个过程中，专注于提高以下关键领域：</p>
<ul>
<li><strong>提高双精度性能</strong>——虽然单精度浮点性能大约是桌面 CPU 性能的十倍，但一些 GPU 计算应用程序也需要更高的双精度性能。</li>
<li><strong>ECC 支持</strong>——ECC 允许 GPU 计算用户在数据中心安装中安全地部署大量 GPU，并确保医疗成像和金融期权定价等数据敏感应用程序免受内存错误的影响。</li>
<li><strong>True Cache Hierarchy</strong>—— 一些并行算法无法使用 GPU 的共享内存，用户需要一个真正的缓存架构来帮助他们。</li>
<li><strong>更多共享内存</strong>——许多 CUDA 程序员要求超过 16 KB 的 SM 共享内存来加速他们的应用程序。</li>
<li><strong>更快的上下文切换</strong>——用户要求在应用程序和更快的图形和计算互操作之间进行更快的上下文切换。</li>
<li><strong>更快的原子操作</strong>(Atomic Operations)——用户要求为他们的并行算法提供更快的读-修改-写原子操作。</li>
</ul>
<p>第一个基于Fermi架构的GPU，使用 30 亿个晶体管实现，共计512个CUDA内核。</p>
<p>这512 个 CUDA 内核被组织成 16 个 SM，每个 SM 是一个<strong>垂直的矩形条带</strong>，分别位于一个普通的 L2 cache周围，每个 SM 有32 个CUDA 内核。</p>
<p><strong>一个CUDA 内核为一个线程在每个时钟周期里执行一条浮点或整数指令</strong>。</p>
<p>6个64-bit显存分区，组成一个384-bit的显存接口，总共支持高达 6GB 的 GDDR5 DRAM显存。</p>
<blockquote>
<p>GDDR5：第五版图形用双倍数据传输率存储器<br>DRAM：动态随机存取存储器</p>
</blockquote>
<p>主机接口(host interface )通过 PCI-Express 将 GPU 连接到 CPU。 Giga Thread 全局调度器将线程块分发给 SM 线程调度器。</p>
<p>整个 GPU 有多个 GPC(图形处理集群)，单个GPC包含一个光栅引擎(Raster Engine)，四个 SM（流式多处理器），GPC 可以被认为是一个独立的 GPU。所有从 Fermi 开始的 NVIDIA GPU，都有 GPC。</p>
<p>SM（Streaming Multiprocessors）是GPU架构中非常重要的部分，GPU硬件的并行性就是由SM决定的。</p>
<h2 id="Kepler架构"><a href="#Kepler架构" class="headerlink" title="Kepler架构"></a>Kepler架构</h2><p>Kepler架构的思路是：减少SM单元数(在这一代中叫SMX单元)，增加每组SM单元中的CUDA内核数。在Kepler架构中，每个SM单元的CUDA内核数由Fermi架构的32个激增至192个。</p>
<p>在每个SMX中：</p>
<ul>
<li>4 个 Warp Scheduler，8 个 Dispatch Unit</li>
<li>绿色：192个 CUDA 内核，分在12条 lane 上，每条分别是 16 个</li>
<li>黄色：64 个DP双精度运算单元，分在4条 lane 上，每条 lane 上 16 个</li>
<li>32 个 LD&#x2F;ST Unit</li>
<li>32 个 SFU</li>
</ul>
<h2 id="Maxwell架构"><a href="#Maxwell架构" class="headerlink" title="Maxwell架构"></a>Maxwell架构</h2><p>Maxwell架构的SM单元和Kepler架构相比，又有很大变化，这一代的SM单元更像是把4个Fermi 架构的SM单元，按照2x2的方式排列在一起，这一代称为SMM单元。</p>
<p>SMM 使用基于象限的设计，具有四个 32 核处理块(processing blocks)，每个处理块都有一个专用的 warp 调度程序，能够在每个时钟分派两条指令。</p>
<p>每个 SMM 单元提供</p>
<ul>
<li>八个纹理单元(texture units)</li>
<li>一个多态引擎(polymorph engine-图形的几何处理)</li>
<li>专用寄存器文件和共享内存。</li>
</ul>
<p>每个处理块中：</p>
<ul>
<li>1个 Warp Scheduler，2 个 Dispatch Unit</li>
<li>绿色：32个 CUDA 内核</li>
<li>8个 LD&#x2F;ST Unit</li>
<li>8个 SFU</li>
</ul>
<p>CUDA内核总数 从Kpler时代的每组SM单元192个减少到了每组128个，但是每个SMM单元将拥有更多的逻辑控制电路，便于精确控制。</p>
<h2 id="Pascal架构"><a href="#Pascal架构" class="headerlink" title="Pascal架构"></a><strong>Pascal架构</strong></h2><p>这里有一个新概念：<strong>核心</strong></p>
<p>NVIDIA不同的架构会有几种不同的核心，Pascal架构有GP100、GP102两种大核心：</p>
<ul>
<li>GP100：3840个CUDA核心，60组SM单元；</li>
<li>GP102：3584个CUDA核心，28组SM单元；</li>
</ul>
<blockquote>
<p>第2组数据存疑</p>
</blockquote>
<p><strong>核心</strong>是一个完整的GPU模组，上图展示了一个pascal架构的GP100核心，带有 60 个 SM 单元。</p>
<p>不同的显卡产品可以使用不同的 GP100 配置，一般是满配或者减配，比如Tesla P100 使用了 56 个 SM 单元。</p>
<p>每个SM单元中，分为2个Process Block，每个Process Block中：</p>
<ul>
<li>1个 Warp Scheduler，2 个 Dispatch Unit</li>
<li>绿色：32个 CUDA 内核</li>
<li><strong>黄色：16 个DP双精度运算单元，分在2条 lane 上，每条 lane 上 8个</strong></li>
<li>8个 LD&#x2F;ST Unit</li>
<li>8个 SFU</li>
</ul>
<p>CUDA内核总数从Maxwell时代的每组SM单元128个减少到了每组64个，这一代最大的特点是又把DP双精度运算单元加回来了。</p>
<p>制程工艺升级到了16nm，性能大幅提升，功耗却不增加。</p>
<h2 id="Volta架构"><a href="#Volta架构" class="headerlink" title="Volta架构"></a><strong>Volta架构</strong></h2><p>每个SM单元中，分为4个Process Block，每个Process Block中：</p>
<ul>
<li>1个 Warp Scheduler，1个 Dispatch Unit</li>
<li>8 个 FP64 Core</li>
<li>16 个 INT32 Core</li>
<li>16 个 FP32 Core</li>
<li>2 个 Tensor Core</li>
<li>8个 LD&#x2F;ST Unit</li>
<li>4个 SFU</li>
</ul>
<p>在前几代架构中：</p>
<p><strong>一个CUDA 内核在每个时钟周期里只能为一个线程执行一条浮点或整数指令</strong>。</p>
<p>但是从Volta架构开始，将一个CUDA 内核拆分为两部分：FP32 和 INT32，好处是在同一个时钟周期里，可以同时执行浮点和整数指令，提高计算速度。</p>
<p>Volta架构在传统的单双精度计算之外还增加了专用的<strong>Tensor Core</strong>张量单元，用于深度学习、AI运算等。</p>
<h2 id="Turing架构"><a href="#Turing架构" class="headerlink" title="Turing架构"></a><strong>Turing架构</strong></h2><p>Turing架构目前一共有三种核心：</p>
<ul>
<li>TU102核心</li>
<li>TU104核心</li>
<li>TU106核心</li>
</ul>
<p>每个SM单元有4个处理块，每个处理块中：</p>
<ul>
<li>1 个 Warp Scheduler，1 个 Dispath Unit</li>
<li>16 个 INT32 Core</li>
<li>16 个 FP32 Core</li>
<li>2 个 Tensor Core</li>
<li>4 个 LD&#x2F;ST Unit</li>
<li>4 个 SFU</li>
</ul>
<p>这一代架构去掉了对FP64的支持。</p>
<h2 id="Ampere架构"><a href="#Ampere架构" class="headerlink" title="Ampere架构"></a><strong>Ampere架构</strong></h2><p>每个SM单元分成4个处理块，每个处理块中：</p>
<ul>
<li>1 个 Warp Scheduler，1 个 Dispatch Unit</li>
<li>8 个 FP64 Core</li>
<li>16 个 FP32 Core</li>
<li>16 个 INT32 Core</li>
<li>1 个 Tensor Core</li>
<li>8 个 LD&#x2F;ST Unit</li>
<li>4 个 SFU</li>
</ul>
<p>这一代架构又把FP64 Core加回来了，同时也是自Volta架构以来的，NVIDIA第三代Tensor技术，保持一代架构更新一次Tensor。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://JrunDing.github.io">JrunDing</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://jrunding.github.io/2023/11/02/NVIDIA-GPU%E6%9E%B6%E6%9E%84/">http://jrunding.github.io/2023/11/02/NVIDIA-GPU%E6%9E%B6%E6%9E%84/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://JrunDing.github.io" target="_blank">JrunDing</a>！</span></div></div><div class="tag_share"><div class="post_share"><div class="social-share" data-image="https://z1.ax1x.com/2023/12/10/piRckct.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#NVIDIA-GPU%E7%9A%84%E6%9E%B6%E6%9E%84%E6%BC%94%E5%8F%98%E5%8E%86%E5%8F%B2%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.</span> <span class="toc-text">NVIDIA GPU的架构演变历史和基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tesla-%E6%9E%B6%E6%9E%84"><span class="toc-number">2.</span> <span class="toc-text">Tesla 架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fermi%E6%9E%B6%E6%9E%84"><span class="toc-number">3.</span> <span class="toc-text">Fermi架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kepler%E6%9E%B6%E6%9E%84"><span class="toc-number">4.</span> <span class="toc-text">Kepler架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Maxwell%E6%9E%B6%E6%9E%84"><span class="toc-number">5.</span> <span class="toc-text">Maxwell架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pascal%E6%9E%B6%E6%9E%84"><span class="toc-number">6.</span> <span class="toc-text">Pascal架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Volta%E6%9E%B6%E6%9E%84"><span class="toc-number">7.</span> <span class="toc-text">Volta架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Turing%E6%9E%B6%E6%9E%84"><span class="toc-number">8.</span> <span class="toc-text">Turing架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ampere%E6%9E%B6%E6%9E%84"><span class="toc-number">9.</span> <span class="toc-text">Ampere架构</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://z1.ax1x.com/2023/12/10/piRckct.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By JrunDing</div><div class="footer_custom_text">Wish to feel nothing.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'http://jrunding.github.io/2023/11/02/NVIDIA-GPU%E6%9E%B6%E6%9E%84/'
    this.page.identifier = '/2023/11/02/NVIDIA-GPU%E6%9E%B6%E6%9E%84/'
    this.page.title = 'NVIDIA GPU架构'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://jrunding.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Disqus' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script><script>if (window.DISQUSWIDGETS === undefined) {
  var d = document, s = d.createElement('script');
  s.src = 'https://jrunding.disqus.com/count.js';
  s.id = 'dsq-count-scr';
  (d.head || d.body).appendChild(s);
} else {
  DISQUSWIDGETS.getCount({reset: true});
}</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>