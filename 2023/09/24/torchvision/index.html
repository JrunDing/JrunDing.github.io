<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>torchvision | JrunDing</title><meta name="author" content="JrunDing"><meta name="copyright" content="JrunDing"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="一、简介​	tochvision主要处理图像数据，包含一些常用的数据集、模型、转换函数等。torchvision独立于PyTorch，需要专门安装。 ​	torchvision主要包含以下四部分：  torchvision.models: 提供深度学习中各种经典的网络结构、预训练好的模型，如：Alex-Net、VGG、ResNet、Inception等。 torchvision.datasets：">
<meta property="og:type" content="article">
<meta property="og:title" content="torchvision">
<meta property="og:url" content="http://jrunding.github.io/2023/09/24/torchvision/index.html">
<meta property="og:site_name" content="JrunDing">
<meta property="og:description" content="一、简介​	tochvision主要处理图像数据，包含一些常用的数据集、模型、转换函数等。torchvision独立于PyTorch，需要专门安装。 ​	torchvision主要包含以下四部分：  torchvision.models: 提供深度学习中各种经典的网络结构、预训练好的模型，如：Alex-Net、VGG、ResNet、Inception等。 torchvision.datasets：">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2023/03/03/ppkg98x.jpg">
<meta property="article:published_time" content="2023-09-24T14:17:48.000Z">
<meta property="article:modified_time" content="2023-09-24T14:18:48.932Z">
<meta property="article:author" content="JrunDing">
<meta property="article:tag" content="Communication, Automation, ML, DL, NLP, CV, Movie, photography">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2023/03/03/ppkg98x.jpg"><link rel="shortcut icon" href="https://z1.ax1x.com/2023/11/13/piJMDnH.jpg"><link rel="canonical" href="http://jrunding.github.io/2023/09/24/torchvision/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: JrunDing","link":"链接: ","source":"来源: JrunDing","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'torchvision',
  isPost: true,
  isHome: false,
  isHighlightShrink: undefined,
  isToc: true,
  postUpdate: '2023-09-24 22:18:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js/themes/blue/pace-theme-minimal.min.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://z1.ax1x.com/2023/11/13/piJMDnH.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">192</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><span> Talk</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span> Music</span></a></div><div class="menus_item"><a class="site-page" href="/movie/"><span> Movie</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s1.ax1x.com/2023/03/03/ppkg98x.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="JrunDing"></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><span> Talk</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span> Music</span></a></div><div class="menus_item"><a class="site-page" href="/movie/"><span> Movie</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">torchvision</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-09-24T14:17:48.000Z" title="发表于 2023-09-24 22:17:48">2023-09-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-09-24T14:18:48.932Z" title="更新于 2023-09-24 22:18:48">2023-09-24</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Computer-Vision/">Computer Vision</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">1.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>6分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="torchvision"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><span class="disqus-comment-count"><a href="http://jrunding.github.io/2023/09/24/torchvision/#disqus_thread"><i class="fa-solid fa-spinner fa-spin"></i></a></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>​	tochvision主要处理图像数据，包含一些常用的<strong>数据集、模型、转换函数</strong>等。torchvision独立于PyTorch，需要专门安装。</p>
<p>​	torchvision主要包含以下四部分：</p>
<ul>
<li>torchvision.models: 提供深度学习中各种经典的网络结构、预训练好的模型，如：Alex-Net、VGG、ResNet、Inception等。</li>
<li>torchvision.datasets：提供常用的数据集，设计上继承 torch.utils.data.Dataset，主要包括：MNIST、CIFAR10&#x2F;100、ImageNet、COCO等。</li>
<li>torchvision.transforms：提供常用的数据预处理操作，主要包括对Tensor及PIL Image对象的操作。</li>
<li>torchvision.utils：工具类，如保存张量作为图像到磁盘，给一个小批量创建一个图像网格。</li>
</ul>
<h2 id="二、安装"><a href="#二、安装" class="headerlink" title="二、安装"></a>二、安装</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip3 install torchvision</span><br></pre></td></tr></table></figure>

<p>​	torchvision要注意与pytorch版本和Cuda相匹配。<br>​	要查询pytorch和torchvision的版本，可以使用下面语句 ：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)</span><br><span class="line"><span class="built_in">print</span>(torchvision.__version__)</span><br></pre></td></tr></table></figure>

<h2 id="三、torchvision的主要功能示例"><a href="#三、torchvision的主要功能示例" class="headerlink" title="三、torchvision的主要功能示例"></a>三、torchvision的主要功能示例</h2><h3 id="1-加载model"><a href="#1-加载model" class="headerlink" title="1.加载model"></a>1.加载model</h3><p>​	1）加载几个预训练模型</p>
<p>​	通过pretrined&#x3D;True可以加载预训练模型。pretrained默认值是False，不赋值和赋值False效果一样。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">resnet18 = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">vgg16 = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line">alexnet = models.alexnet(pretrained=<span class="literal">True</span>)</span><br><span class="line">squeezenet = models.squeezenet1_0(pretrained=<span class="literal">True</span>)</span><br><span class="line">densenet = models.densenet_161()</span><br></pre></td></tr></table></figure>

<p>​	预训练模型期望的输入：</p>
<ul>
<li>RGB图像的mini-batch：(batch_size, 3, H, W)，并且H和W不能低于224。</li>
<li>图像的像素值必须在范围[0,1]间，并且用均值mean&#x3D;[0.485, 0.456, 0.406]和方差std&#x3D;[0.229, 0.224, 0.225]进行标准化。</li>
</ul>
<p>​	下载的模型可以通过state_dict() 来打印状态参数、缓存的字典。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">vgg16 = models.vgg16(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 返回包含模块所有状态的字典，包括参数和缓存</span></span><br><span class="line">pretrained_dict = vgg16.state_dict()</span><br></pre></td></tr></table></figure>

<p>​	2）只加载模型，不加载预训练参数 如果只需要网络结构，不需要训练模型的参数来初始化，可以将pretrained &#x3D; False</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入模型结构</span></span><br><span class="line">resnet18 = models.resnet18(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 加载预先下载好的预训练参数到resnet18</span></span><br><span class="line">resnet18.load_state_dict(torch.load(<span class="string">&#x27;resnet18-5c106cde.pth&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>​	3）加载部分预训练模型</p>
<p>​	实际使用中可能会对预训练模型进行调节，就是对预训练模型中的层进行修改。</p>
<p>​	下面示例中，对原模型中不匹配的键进行了删除 ， 注意新模型改变了的层需要和原模型对应层的名字不一样，比如：resnet最后一层的名字是fc(PyTorch中)，那么我们修改过的resnet的最后一层就不能取这个名字，可以叫fc_</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line">resnet152 = models.resnet152(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 提取参数</span></span><br><span class="line">pretrained_dict = resnet152.state_dict()</span><br><span class="line"><span class="comment"># 预训练模型也可以通过model_zoo下载参数</span></span><br><span class="line"><span class="comment"># pretrained_dict = model_zoo.load_url(model_urls[&#x27;resnet152&#x27;])</span></span><br><span class="line">model_dict = resnet152.state_dict()</span><br><span class="line"><span class="comment"># 将pretrained_dict里不属于model_dict的键剔除掉</span></span><br><span class="line">pretrained_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items() <span class="keyword">if</span> k <span class="keyword">in</span> model_dict&#125;</span><br><span class="line"><span class="comment"># 更新现有的model_dict</span></span><br><span class="line">model_dict.update(pretrained_dict)</span><br><span class="line"><span class="comment"># 加载真正需要的state_dict</span></span><br><span class="line">resnet152.load_state_dict(model_dict)</span><br></pre></td></tr></table></figure>

<p>​	4）调整模型</p>
<p>​	预训练的模型有些层并不是直接能用，需要我们微微改一下，比如，resnet最后的全连接层是分1000类，而我们只有21类；或resnet第一层卷积接收的通道是3， 我们可能输入图片的通道是4，那么可以通过以下方法修改：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 修改通道数</span></span><br><span class="line">resnet.conv1 = nn.Conv2d(<span class="number">4</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 这里的21即是分类</span></span><br><span class="line">resnet.fc = nn.Linear(<span class="number">2048</span>, <span class="number">21</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="comment"># 加载预训练好的模型，保存到 ~/.torch/models/ 下面</span></span><br><span class="line">resnet34 = models.resnet34(pretrained=<span class="literal">True</span>, num_classes=<span class="number">1000</span>)</span><br><span class="line"><span class="comment"># 默认是ImageNet上的1000分类，这里修改最后的全连接层为10分类问题</span></span><br><span class="line">resnet34.fc = nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-加载数据集"><a href="#2-加载数据集" class="headerlink" title="2.加载数据集"></a>2.加载数据集</h3><p>​	torchvision.datasets是从torch.utils.data.Dataset的子类，可以使用torch.utils.data.DataLoader进行多线程处理。官网参考地址：<a href="https://link.zhihu.com/?target=https://pytorch.org/vision/stable/datasets.html%23">https://pytorch.org/vision/stab</a></p>
<p>​	1）示例：加载MNIST</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line">dataset = datasets.MNIST(<span class="string">&#x27;data/&#x27;</span>, download=<span class="literal">True</span>, train=<span class="literal">False</span>, transform=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<img src="https://z1.ax1x.com/2023/09/24/pP7iTMj.jpg" style="zoom:50%;" />

<p>​	2）示例：加载Fashion-MNIST</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line">dataset = datasets.FashionMNIST(<span class="string">&#x27;data/&#x27;</span>, download=<span class="literal">True</span>, train=<span class="literal">False</span>, transform=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>​	3）ImageFolder实现数据导入</p>
<p>​	datasets.ImageFolder方法可以实现数据导入。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ImageFolder(root,transform=<span class="literal">None</span>,target_transform=<span class="literal">None</span>,loader=default_loader)</span><br></pre></td></tr></table></figure>

<p>​	参数说明：</p>
<ul>
<li>root : 在指定的root路径下面寻找图片。</li>
<li>transform: 接收PIL图像的函数&#x2F;转换并返回已转换的版本。 可以直接使用上面的Compose方法组合需要的变换。</li>
<li>target_transform :对label进行变换。</li>
<li>loader: 指定加载图片的函数，默认操作是读取PIL image对象。</li>
</ul>
<p>​	这个方法返回的是list，可以使用data.DataLoader转成Tensor数据。</p>
<p>​	示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data_transforms = &#123;    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([        </span><br><span class="line">                               transforms.RandomResizedCrop(<span class="number">224</span>), <span class="comment">#Random cutting of an image (224, 224) from the original image        </span></span><br><span class="line">                               transforms.RandomHorizontalFlip(), <span class="comment">#Reversal at 0.5 probability level        </span></span><br><span class="line">                               transforms.ToTensor(),  <span class="comment">#Convert a PIL. Image with a range of [0,255] or numpy. ndarray to a shape of [C, H, W], and a FloadTensor with a range of [0,1.0].        </span></span><br><span class="line">                               transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]) <span class="comment">#Normalization    </span></span><br><span class="line">                               ]),    </span><br><span class="line">                       <span class="string">&#x27;val&#x27;</span>: transforms.Compose([        </span><br><span class="line">                               transforms.Resize(<span class="number">256</span>),        </span><br><span class="line">                               transforms.CenterCrop(<span class="number">224</span>),        </span><br><span class="line">                               transforms.ToTensor(),        </span><br><span class="line">                               transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])    </span><br><span class="line">                               ]),&#125; <span class="comment">#image data </span></span><br><span class="line">filedata_root = <span class="string">&#x27;&#x27;</span></span><br><span class="line">image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_root, x),     </span><br><span class="line">                  data_transforms[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">                  <span class="comment"># wrap your data and label into Tensor</span></span><br><span class="line">                  dataloders = &#123;x: torch.utils.data.DataLoader(image_datasets[x],</span><br><span class="line">                  batch_size=<span class="number">10</span>, </span><br><span class="line">                  shuffle=<span class="literal">True</span>,                                             </span><br><span class="line">                  num_workers=<span class="number">4</span>) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>​	dataloaders 是Variable类型，可以作为模型的输入参数。</p>
<h3 id="3-transforms"><a href="#3-transforms" class="headerlink" title="3.transforms"></a>3.transforms</h3><p>​	transforms包含了一些图像预处理操作，这些操作可以使用torchvison.transforms.Compose连在一起进行串行 操作。这些操作有：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">__all__ = [<span class="string">&quot;Compose&quot;</span>, <span class="string">&quot;ToTensor&quot;</span>, <span class="string">&quot;ToPILImage&quot;</span>, <span class="string">&quot;Normalize&quot;</span>, <span class="string">&quot;Resize&quot;</span>, <span class="string">&quot;Scale&quot;</span>, <span class="string">&quot;CenterCrop&quot;</span>, <span class="string">&quot;Pad&quot;</span>,</span><br><span class="line">           <span class="string">&quot;Lambda&quot;</span>, <span class="string">&quot;RandomApply&quot;</span>, <span class="string">&quot;RandomChoice&quot;</span>, <span class="string">&quot;RandomOrder&quot;</span>, <span class="string">&quot;RandomCrop&quot;</span>, <span class="string">&quot;RandomHorizontalFlip&quot;</span>, </span><br><span class="line">           <span class="string">&quot;RandomVerticalFlip&quot;</span>, <span class="string">&quot;RandomResizedCrop&quot;</span>, <span class="string">&quot;RandomSizedCrop&quot;</span>, <span class="string">&quot;FiveCrop&quot;</span>, <span class="string">&quot;TenCrop&quot;</span>, 		         <span class="string">&quot;LinearTransformation&quot;</span>,           </span><br><span class="line">           <span class="string">&quot;ColorJitter&quot;</span>, <span class="string">&quot;RandomRotation&quot;</span>, <span class="string">&quot;RandomAffine&quot;</span>, <span class="string">&quot;Grayscale&quot;</span>, <span class="string">&quot;RandomGrayscale&quot;</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>Compose()：用来管理所有的transforms操作。</li>
<li>ToTensor()：把图片数据转换成张量并转化范围在[0,1]区间内。</li>
<li>Normalize(mean, std)：归一化。</li>
<li>Resize(size)：输入的PIL图像调整为指定的大小，参数可以为int或int元组。</li>
<li>CenterCrop(size)：将给定的PIL Image进行中心切割，得到指定size的tuple。</li>
<li>RandomCrop(size, padding&#x3D;0)：随机中心点切割。</li>
<li>RandomHorizontalFlip(size, interpolation&#x3D;2)：将给定的PIL Image随机切割，再resize。</li>
<li>RandomHorizontalFlip()：随机水平翻转给定的PIL Image。</li>
<li>RandomVerticalFlip()：随机垂直翻转给定的PIL Image。</li>
<li>ToPILImage()：将Tensor或numpy.ndarray转换为PIL Image。</li>
<li>FiveCrop(size)：将给定的PIL图像裁剪成4个角落区域和中心区域。</li>
<li>Pad(padding, fill&#x3D;0, padding_mode&#x3D;‘constant’)：对PIL边缘进行填充。</li>
<li>RandomAffine(degrees, translate&#x3D;None, scale&#x3D;None)：保持中心不变的图片进行随机仿射变化。</li>
<li>RandomApply(transforms, p&#x3D;0.5)：随机选取变换。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://JrunDing.github.io">JrunDing</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://jrunding.github.io/2023/09/24/torchvision/">http://jrunding.github.io/2023/09/24/torchvision/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://JrunDing.github.io" target="_blank">JrunDing</a>！</span></div></div><div class="tag_share"><div class="post_share"><div class="social-share" data-image="https://s1.ax1x.com/2023/03/03/ppkg98x.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="disqus_thread"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">一、简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85"><span class="toc-number">2.</span> <span class="toc-text">二、安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81torchvision%E7%9A%84%E4%B8%BB%E8%A6%81%E5%8A%9F%E8%83%BD%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.</span> <span class="toc-text">三、torchvision的主要功能示例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%8A%A0%E8%BD%BDmodel"><span class="toc-number">3.1.</span> <span class="toc-text">1.加载model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.2.</span> <span class="toc-text">2.加载数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-transforms"><span class="toc-number">3.3.</span> <span class="toc-text">3.transforms</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://s1.ax1x.com/2023/03/03/ppkg98x.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By JrunDing</div><div class="footer_custom_text">Wish to feel nothing.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>function loadDisqus () {
  var disqus_config = function () {
    this.page.url = 'http://jrunding.github.io/2023/09/24/torchvision/'
    this.page.identifier = '/2023/09/24/torchvision/'
    this.page.title = 'torchvision'
  };

  window.disqusReset = () => {
    DISQUS.reset({
      reload: true,
      config: disqus_config
    })
  }

  if (window.DISQUS) disqusReset()
  else {
    (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://jrunding.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  }

  document.getElementById('darkmode').addEventListener('click', () => {
    setTimeout(() => window.disqusReset(), 200)
  })
}

if ('Disqus' === 'Disqus' || !false) {
  if (false) btf.loadComment(document.getElementById('disqus_thread'), loadDisqus)
  else loadDisqus()
} else {
  function loadOtherComment () {
    loadDisqus()
  }
}
</script><script>if (window.DISQUSWIDGETS === undefined) {
  var d = document, s = d.createElement('script');
  s.src = 'https://jrunding.disqus.com/count.js';
  s.id = 'dsq-count-scr';
  (d.head || d.body).appendChild(s);
} else {
  DISQUSWIDGETS.getCount({reset: true});
}</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>